{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2oP1uun77cIh"
   },
   "source": [
    "# Assignment 1\n",
    "\n",
    "This assignment will involve the creation of a spellchecking system and an evaluation of its performance. You may use the code snippets provided in Python for completing this or you may use the programming language or environment of your choice\n",
    "\n",
    "Please start by downloading the corpus `holbrook.txt` from Blackboard\n",
    "\n",
    "The file consists of lines of text, with one sentence per line. Errors in the line are marked with a `|` as follows\n",
    "\n",
    "    My siter|sister go|goes to Tonbury .\n",
    "    \n",
    "In this case the word 'siter' was corrected to 'sister' and the word 'go' was corrected to 'goes'.\n",
    "\n",
    "In some places in the corpus two words maybe corrected to a single word or one word to a multiple words. This is denoted in the data using underscores e.g.,\n",
    "\n",
    "    My Mum goes out some_times|sometimes .\n",
    "    \n",
    "For the purpose of this assignment you do not need to separate these words, but instead you may treat them like a single token.\n",
    "\n",
    "*Note: you may use any functions from NLTK to complete the assignment. It should not be necessary to use other libraries and so please consult with us if your solution involves any other external library. If you use any function from NLTK in Task 6 please include a brief description of this function and how it contributes to your solution.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student: Gerard Larkin\n",
    "### Student Number: 20235986"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIVCSJV-7kDs"
   },
   "source": [
    "## Task 1 (10 Marks)\n",
    "\n",
    "Write a parser that can read all the lines of the file `holbrook.txt` and print out for each line the original (misspelled) text, the corrected text and the indexes of any changes. The indexes refers to the index of the words in the sentence. In the example given, there is only an error in the 10th word and so the list of indexes is [9]. It is not necessary to analyze where the error occurs inside the word.\n",
    "\n",
    "Then split your data into a test set of 100 lines and a training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "RznCZ1mw7mfk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'original': ['I', 'have', 'four', 'in', 'my', 'Family', 'Dad', 'Mum', 'and', 'siter', '.'], 'corrected': ['I', 'have', 'four', 'in', 'my', 'Family', 'Dad', 'Mum', 'and', 'sister', '.'], 'indexes': [9]}, {'original': ['My', 'Dad', 'works', 'at', 'Melton', '.'], 'corrected': ['My', 'Dad', 'works', 'at', 'Melton', '.'], 'indexes': []}, {'original': ['My', 'siter', 'go', 'to', 'Tonbury', '.'], 'corrected': ['My', 'sister', 'goes', 'to', 'Tonbury', '.'], 'indexes': [1, 2]}]\n"
     ]
    }
   ],
   "source": [
    "lines = open(\"holbrook.txt\").readlines()\n",
    "data = []\n",
    "# Write your code here\n",
    "for line in lines:\n",
    "    # create a dictionary with 3 keys: original, corrected, indexes\n",
    "    dct = {}\n",
    "    i = list(line.split())\n",
    "    o_str = []\n",
    "    for a in i:      \n",
    "        if '|' in a:\n",
    "            a1 = a.replace(a, a.split('|')[0])\n",
    "            o_str.append(a1)\n",
    "        else:\n",
    "            a\n",
    "            o_str.append(a)\n",
    "    dct.update({'original': o_str})\n",
    "    c_str = []\n",
    "    for b in i:\n",
    "        if '|' in b:\n",
    "            b1 = b.replace(b, b.split('|')[1])\n",
    "            c_str.append(b1)\n",
    "        else:\n",
    "            b\n",
    "            c_str.append(b)\n",
    "    dct.update({'corrected': c_str}) \n",
    "    i_str = ([c for c in range(len(o_str)) if o_str[c] != c_str[c]])\n",
    "    dct.update({'indexes': i_str})\n",
    "    \n",
    "    data.append(dct)\n",
    "\n",
    "    \n",
    "print(data[2:5])\n",
    "assert(data[2] == {\n",
    "    'original': ['I', 'have', 'four', 'in', 'my', 'Family', 'Dad', 'Mum', 'and', 'siter', '.'], \n",
    "    'corrected': ['I', 'have', 'four', 'in', 'my', 'Family', 'Dad', 'Mum', 'and', 'sister', '.'], \n",
    "    'indexes': [9]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eRSX4I0H7pSC"
   },
   "source": [
    "The counts and assertions given in the following sections are based on splitting the training and test set as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Kt9aR2Gy7p1C"
   },
   "outputs": [],
   "source": [
    "test = data[:100]\n",
    "train = data[100:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hm5JL7cH7sLK"
   },
   "source": [
    "## **Task 2** (10 Marks): \n",
    "Calculate the frequency (number of occurrences), *ignoring case*, of all words and their unigram probability from the corrected *training* sentences.\n",
    "\n",
    "*Hint: use `Counter` to implement this so it may be called many times*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7ge0uHS-7uEK"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "correct_words = [i.lower() for j in [k['corrected'] for k in train] for i in j]\n",
    "\n",
    "def unigram(word):\n",
    "    # Write your code here.\n",
    "    if isinstance(word, str):\n",
    "        cnt = Counter()\n",
    "        for i in correct_words:\n",
    "            cnt[i] += 1\n",
    "        dct = dict(cnt)     \n",
    "        return dct[word]\n",
    "\n",
    "    if isinstance(word, list):\n",
    "        cnt = Counter()\n",
    "        for i in correct_words:\n",
    "            if i in word:\n",
    "                cnt[i] += 1\n",
    "        dct = dict(cnt)           \n",
    "        return dct\n",
    "\n",
    "def prob(word):\n",
    "    # Write your code here.\n",
    "    if isinstance(word, str):\n",
    "        return unigram(word) / len(correct_words)\n",
    "    \n",
    "    word_prob = {}\n",
    "    if isinstance(word, list):\n",
    "        for k, v in unigram(word).items():      \n",
    "            word_prob.update({k : v / len(correct_words)})    \n",
    "        return word_prob\n",
    "    \n",
    "# Test your code with the following\n",
    "assert(unigram(\"me\")==87)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w8r8QYj78GPK"
   },
   "source": [
    "## **Task 3** (15 Marks): \n",
    "[Edit distance](https://en.wikipedia.org/wiki/Edit_distance) is a method that calculates how similar two strings are to one another by counting the minimum number of operations required to transform one string into the other. There is a built-in implementation in NLTK that works as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 956,
     "status": "ok",
     "timestamp": 1536070558621,
     "user": {
      "displayName": "John McCrae",
      "photoUrl": "//lh3.googleusercontent.com/-whXIBV_wL0Y/AAAAAAAAAAI/AAAAAAAAATE/-2hfaPZsyHM/s50-c-k-no/photo.jpg",
      "userId": "102173405218988557336"
     },
     "user_tz": -60
    },
    "id": "SV9Mu8P38IQE",
    "outputId": "9f29e22b-0f8b-4b92-9d5f-fcde3efec970"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "from nltk.metrics.distance import edit_distance\n",
    "\n",
    "# Edit distance returns the number of changes to transform one word to another\n",
    "print(edit_distance(\"sister\", \"popular\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hm46Lbiz8K8M"
   },
   "source": [
    "Write a function that calculates all words with *minimal* edit distance to the misspelled word. You should do this as follows\n",
    "\n",
    "1. Collect the set of all unique tokens in `train`\n",
    "2. Find the minimal edit distance, that is the lowest value for the function `edit_distance` between `token` and a word in `train`\n",
    "3. Output all unique words in `train` that have this same (minimal) `edit_distance` value\n",
    "\n",
    "*Do not implement edit distance, use the built-in NLTK function `edit_distance`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HoilAmFW8PCb"
   },
   "outputs": [],
   "source": [
    "def get_candidates(token):\n",
    "    dct = {}\n",
    "    dist = []\n",
    "    tok = [i.lower() for i in token]\n",
    "    # creates a set of words in same order as list\n",
    "    # http://www.martinbroadhurst.com/removing-duplicates-from-a-list-while-preserving-order-in-python.html\n",
    "    words = set()\n",
    "    corrected = [i for i in correct_words if not (i in words or words.add(i))] \n",
    "    for i in corrected:\n",
    "        dct.update({i : edit_distance(tok, i)})\n",
    "        dist.append(edit_distance(tok, i))\n",
    "        \n",
    "    return [i for i, j in dct.items() if j == min(dist)] # dict comprehension to return keys based on a particular value\n",
    "\n",
    "# Test your code as follows\n",
    "assert(get_candidates(\"minde\") == ['mine', 'mind'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGY-eCkN8TIM"
   },
   "source": [
    "## Task 4 (15 Marks):\n",
    "\n",
    "Write a function that takes a (misspelled) sentence and returns the corrected version of that sentence. The system should scan the sentence for words that are not in the dictionary (set of unique words in the training set) and for each word that is not in the dictionary choose a word in the dictionary that has minimal edit distance and has the highest *unigram probability*. \n",
    "\n",
    "*Your solution to this should involve `get_candidates`*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dIGKE4_P8WGP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'white', 'cat']\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "def correct(sentence):\n",
    "    # Write your code here\n",
    "    corrected_sentence = []\n",
    "    for i in sentence:\n",
    "        if i in correct_words: # correct_words is list of corrected words in the training set \n",
    "            corrected_sentence.append(i)\n",
    "        else:\n",
    "            l = [i for i, j in prob(get_candidates(i)).items() if j == max(prob(get_candidates(i)).values())] # don't change\n",
    "            # in case more than one word is returned from previous step, I will arbirtrarily choose the word that is the \n",
    "            # same length as the misspelled word (doesn't appear to be needed)\n",
    "            if len(l) == 1:\n",
    "                for k in l:\n",
    "                    corrected_sentence.append(k)\n",
    "            else:\n",
    "                for k, v in prob(get_candidates(i)).items():\n",
    "                    if len(k) == len(i):\n",
    "                        corrected_sentence.append(k)\n",
    "                \n",
    "    return corrected_sentence\n",
    "\n",
    "print(correct([\"this\",\"whitr\",\"cat\"]))\n",
    "print(\"-------------------------\")\n",
    "assert(correct([\"this\",\"whitr\",\"cat\"]) == ['this','white','cat'])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oG7jC6au8kka"
   },
   "source": [
    "## **Task 5** (10 Marks): \n",
    "Using the test corpus evaluate the *accuracy* of your method, i.e., how many words from your system's output match the corrected sentence (you should count words that are already spelled correctly and not changed by the system)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 539,
     "status": "ok",
     "timestamp": 1536071822989,
     "user": {
      "displayName": "John McCrae",
      "photoUrl": "//lh3.googleusercontent.com/-whXIBV_wL0Y/AAAAAAAAAAI/AAAAAAAAATE/-2hfaPZsyHM/s50-c-k-no/photo.jpg",
      "userId": "102173405218988557336"
     },
     "user_tz": -60
    },
    "id": "HSXTQypR8mdR",
    "outputId": "853813e4-d71b-42a7-8e96-68d038457628"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy Full Corpus: 96.11%', 'Accuracy Set Corpus: 82.24%')\n"
     ]
    }
   ],
   "source": [
    "def accuracy(test):\n",
    "    # Write your code here\n",
    "    test_corr = [[j.lower() for j in i] for i in [k['corrected'] for k in test]]\n",
    "    test_model_corr = []\n",
    "    for i in range(len(test)):\n",
    "        ol = test[i]['original']\n",
    "        il = test[i]['indexes']\n",
    "        rl = [ol[i] for i in il]\n",
    "        rpl_l = correct(rl)\n",
    "        for (i, rpl_l) in zip(il, rpl_l):\n",
    "            ol[i] = rpl_l\n",
    "        test_model_corr.append(ol)\n",
    "    \n",
    "    # flatten lists for comparison\n",
    "    same_words = 0\n",
    "    test_corr_flat = [i for j in test_corr for i in j]\n",
    "    test_model_corr_flat = [i for j in test_model_corr for i in j]\n",
    "    for i in test_corr_flat:\n",
    "        if i in test_model_corr_flat:\n",
    "            same_words += 1\n",
    "    \n",
    "    # accuracy of full corpus\n",
    "    acc = \"Accuracy Full Corpus: \" + str(round(((same_words *100) / len(test_corr_flat)),2)) + \"%\"\n",
    "        \n",
    "    # accuracy of set corpus\n",
    "    set_test_corr_flat = set(test_corr_flat)\n",
    "    set_test_model_corr_flat = set(test_model_corr_flat)\n",
    "    same_set_words = 0\n",
    "    for i in set_test_corr_flat:\n",
    "        if i in set_test_model_corr_flat:\n",
    "            same_set_words += 1\n",
    "    \n",
    "    acc_set = \"Accuracy Set Corpus: \" + str(round(((same_set_words *100) / len(set_test_corr_flat)),2)) + \"%\"\n",
    "    \n",
    "    return acc, acc_set\n",
    "\n",
    "print(accuracy(train))\n",
    "# Results of running train data through model: ('Accuracy Full Corpus: 96.11%', 'Accuracy Set Corpus: 82.24%')\n",
    "# Results of running test data through model: ('Accuracy Full Corpus: 86.63%', 'Accuracy Set Corpus: 73.2%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9b-r2JzD8_Zh"
   },
   "source": [
    "## **Task 6 (35 Marks):**\n",
    "\n",
    "Consider a modification to your algorithm that would improve the accuracy of the algorithm developed in Task 3 and 4\n",
    "\n",
    "* You may resources beyond those provided here.\n",
    "* You must **not use the test data** in this task.\n",
    "* Provide a short text describing what you intend to do and why. \n",
    "* Full marks for this section may be obtained without an implementation, but an implementation is preferred.\n",
    "* Your implementation should not consist of more than 50 lines of code\n",
    "\n",
    "Please note this task is marked according to: demonstration of knowledge from the lectures (10), originality and appropriateness of solution (10), completeness of description (10) and technical correctness (5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of implementation of improvement to corpus correction model\n",
    "\n",
    "Our previous model was concerned with correcting spelling mistakes based on unigram probability(max probability of the word in the corpus and the minimum edit distance of altering one word to another) of a token in the corpus. This model was limited in that it only considered words in our small corpus and if a mis-spelled word did not have a corresponding word it could compare itself to it, e.g. 'consulatoin', it would ignore it.\n",
    "\n",
    "We can imporve the accuracy of the model by increasing the list of words that we can compare our corpus against. This is done simply by calling the built-in nltk.corpus words.words().\n",
    "However we need to mindful that every corpus has unique/specific words to that corpus that may not be in commom usage e.g. 'enflield'. We need to therefore ensure that this word is not corrected. I do this by setting a threshold limit of frequency of word the in the corpus being 2 or less when looking for words that are mis-spelled. If a word is not in the larger corpus and it only occurs once there is a high probability it is mis-spelled. Additonally, setting the threshold to 2 where the word is not in the larger corpus is indicative of the same spelling error occuring. I then run the word through a third party spellchecker module called 'autocorrect'.  \n",
    "\n",
    "I then attempted to substitute bigrams with low proability in the small corpus with bigrams with a higher probability in the larger corpus based on the following:\n",
    "* if the POS tag of the first token in the small corpus bigram tuple matches the POS tag in the first token of a large corpus bigram tuple\n",
    "* and if the edit_distince of the second token in both bigrams was 1 at a maximum\n",
    "* and the freq_dist (could not figure out how to calculate pmi, nor us the built-in pmi measure in nltk) of that token from the large corpus was the highest freq_dist out of all possible candidates\n",
    "\n",
    "The large corpus of bigrams I will use is taken from https://norvig.com/ngrams/\n",
    "The total number of bigrams in the this corpus is 314,843,401 as stated here https://ai.googleblog.com/2006/08/all-our-n-gram-are-belong-to-you.html\n",
    "\n",
    "#### Result: \n",
    "I did not get the improvement on the model to work as intended. If I just keep to the additional spell checker part of the improved model the accuracy on the train data is actually less than when I originally ran the train data through the original model. I struggled to get the sought after bigram replacement after setting the conditions on which a bigram should be replaced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Correct data as per our original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_corr = []\n",
    "orig_words = [[j.lower() for j in i] for i in [k['original'] for k in train]]\n",
    "for i in range(len(orig_words)):\n",
    "    ol = orig_words[i]\n",
    "    il = train[i]['indexes']\n",
    "    rl = [ol[i] for i in il]\n",
    "    rpl_l = correct(rl) # first correct words as per the previously built model\n",
    "    for (i, rpl_l) in zip(il, rpl_l):\n",
    "        ol[i] = rpl_l\n",
    "    test_model_corr.append(ol)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get frequency of each word in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_corr_words = [i for j in test_model_corr for i in j]\n",
    "word_freq = dict()\n",
    "for word in mod_corr_words:\n",
    "    if word in word_freq:\n",
    "        word_freq[word] += 1\n",
    "    else:\n",
    "        word_freq[word] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correct spelling using autocorrect: https://github.com/fsondej/autocorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "from autocorrect import Speller\n",
    "spell = Speller()\n",
    "spell_test_model_corr = []\n",
    "for i in test_model_corr:\n",
    "    sub_list = []\n",
    "    for j in i:\n",
    "        # choosing a freq threshold of 2, if the freq of a word is 1 and it is not in words the most likely spelling error, additionally \n",
    "        # spelling errors are repeated on the same word, but want to leave the threshold low so that I don;t include corpus specific words\n",
    "        if word_freq[j] <= 2 and j not in words.words():\n",
    "            k = spell(j)\n",
    "            sub_list.append(k)\n",
    "        else:\n",
    "            sub_list.append(j)\n",
    "    spell_test_model_corr.append(sub_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace n-grams (bigram) in corpus with low probability of occuring with n-gram with higher probability in larger corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.collocations import *\n",
    "from nltk.corpus import brown\n",
    "import collections\n",
    "\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "\n",
    "text = open(\"ngrams/count_2w.txt\").readlines()\n",
    "big_corpus_bg_score = [] #need\n",
    "for i in text:\n",
    "    i = i.replace(\"\\t\",\" \").replace(\"\\n\",\"\")\n",
    "    i = i.split()\n",
    "    i[2] = int(i[2])/314843401\n",
    "    big_corpus_bg_score.append(i)\n",
    "    \n",
    "corpus_bg = BigramCollocationFinder.from_words([i.lower() for j in spell_test_model_corr for i in j])\n",
    "\n",
    "corpus_word_fd = nltk.FreqDist([i.lower() for j in spell_test_model_corr for i in j])\n",
    "corpus_bigram_fd = nltk.FreqDist(nltk.bigrams([i.lower() for j in spell_test_model_corr for i in j]))\n",
    "\n",
    "corpus_bg = BigramCollocationFinder(corpus_word_fd, corpus_bigram_fd)\n",
    "score_corpus_bg = corpus_bg.score_ngrams(bigram_measures.raw_freq) \n",
    "\n",
    "lst1 = [list(i[0]) for i in score_corpus_bg]\n",
    "lst2 = [i[1] for i in score_corpus_bg]\n",
    "corpus_bg_score = [[j, *k, i] for i,(j, *k) in zip(lst2, lst1)] #maybe need\n",
    "\n",
    "corpus_bg_tag_0 = nltk.pos_tag([x[0] for x in corpus_bg_score]) # ('9.30', 'CD'), ('abc', 'NN')\n",
    "corpus_bg_tag_1 = nltk.pos_tag([x[1] for x in corpus_bg_score])\n",
    "\n",
    "corpus_bg_tags = [(i,j) for i, j in zip(corpus_bg_tag_0, corpus_bg_tag_1)] # (('9.30', 'CD'), ('a.m.', 'RB')), (('abc', 'NN'), ('crazy', 'JJ')) #need\n",
    "\n",
    "big_corpus_bg_tag_0 = nltk.pos_tag([x[0] for x in big_corpus_bg_score])\n",
    "big_corpus_bg_tag_1 = nltk.pos_tag([x[1] for x in big_corpus_bg_score])\n",
    "\n",
    "big_corpus_bg_tags = [(i,j) for i, j in zip(big_corpus_bg_tag_0, big_corpus_bg_tag_1)] #need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_spell_test_model_corr = []\n",
    "for i, j in zip(corpus_bg_score, big_corpus_bg_score):\n",
    "    # check if full bigram with tags match to bigram from larger corpus, if so add back as most likely correct\n",
    "    if i == j: \n",
    "        k = j[0][0],j[1][0]\n",
    "        bigram_spell_test_model_corr.append(k)\n",
    "    # check if first element of the bigram matches and if tag of first element matches and the second bigram element does \n",
    "    # not match and the tag of second element does not match and if edit_distance of second tag = 1 and then take result with highest frequency\n",
    "    # get max freq bigram from a list of potential candidate bigrams \n",
    "    #max_freq_bg = [j for j in big_corpus_bg_score if j[0][1] == max(j[0][1])]\n",
    "    if i[0][0] == j[0][0] and i[0][1] == j[0][1] and \\\n",
    "        i[1][0] != j[1][0] and i[1][1] != j[1][1] and \\\n",
    "        edit_distance(i[1][0],j[1][0]) == 1:\n",
    "            k = j[0][0],j[1][0]\n",
    "            bigram_spell_test_model_corr.append(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLzaC6D28sK9"
   },
   "source": [
    "## **Task 7 (5 Marks):**\n",
    "\n",
    "Repeat the evaluation (as in Task 5) of your new algorithm and show that it outperforms the algorithm from Task 3 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Full Corpus: 91.6%\n",
      "Accuracy Set Corpus: 0.33%\n"
     ]
    }
   ],
   "source": [
    "same_words = 0\n",
    "corr_flat_list = correct_words\n",
    "model_corr_flat_list = [i for j in spell_test_model_corr for i in j]\n",
    "for i, j in zip(corr_flat_list, model_corr_flat_list):\n",
    "    if i == j:\n",
    "        same_words += 1\n",
    "\n",
    "set_same_words = 0\n",
    "set_corr_flat_list = set(corr_flat_list)\n",
    "set_model_corr_flat_list = set(model_corr_flat_list)\n",
    "for i, j in zip(set_corr_flat_list, set_model_corr_flat_list):\n",
    "    if i == j:\n",
    "        set_same_words += 1\n",
    "\n",
    "# accuracy of full corpus\n",
    "print(\"Accuracy Full Corpus: \" + str(round(((same_words) / len(corr_flat_list)) * 100,2)) + \"%\") # Accuracy Full Corpus: 91.58%\n",
    "# accuracy of set corpus\n",
    "print(\"Accuracy Set Corpus: \" + str(round(((set_same_words) / len(set_corr_flat_list)) * 100 ,2)) + \"%\") # Accuracy Set Corpus: 87.67%"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "CT5120/CT5146 - Assignment 1",
   "provenance": [
    {
     "file_id": "12crGPce24mcgITZPs7hU_9CPnLAcyIq6",
     "timestamp": 1603097790764
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
